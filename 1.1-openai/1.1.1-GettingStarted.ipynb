{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000001F8666DC170> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F8666E44A0> root_client=<openai.OpenAI object at 0x000001F86654C6E0> root_async_client=<openai.AsyncOpenAI object at 0x000001F8666DC470> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a subset of artificial intelligence technologies designed to generate content. This can include text, images, music, videos, and more, often based on patterns and data it has been trained on. Unlike traditional AI, which mainly focuses on analysis and pattern recognition, generative AI creates new content by learning from existing data.\\n\\nOne of the key features of generative AI is its ability to produce novel outputs. Techniques like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer models such as GPT (Generative Pre-trained Transformer) are commonly used in this field. These models can be trained on vast datasets to understand the intricacies of language, visual styles, or sound patterns, enabling them to produce coherent and contextually relevant outputs.\\n\\nApplications of generative AI are diverse, ranging from creating art and music to writing articles, generating code, designing products, and even simulating real-world scenarios. While it offers powerful capabilities, it also raises ethical and practical concerns, such as the potential for misuse in producing deepfakes or generating misleading information.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 13, 'total_tokens': 234, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ede7237-3159-4bed-8305-42beee2c0635-0', usage_metadata={'input_tokens': 13, 'output_tokens': 221, 'total_tokens': 234, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform developed by LangChain, designed to help developers build, evaluate, and monitor applications powered by large language models (LLMs). It offers a suite of tools and features that facilitate the creation of more reliable and effective LLM-driven applications. Key features of Langsmith include:\\n\\n1. **Testing and Evaluation**: Langsmith provides capabilities to systematically test and evaluate language model outputs, ensuring they meet the desired quality and reliability standards.\\n\\n2. **Monitoring**: The platform includes monitoring tools that allow developers to track the performance and behavior of their applications in real-time. This helps in identifying issues and opportunities for improvement.\\n\\n3. **Feedback Loop**: By collecting and analyzing user feedback, Langsmith helps in refining and optimizing the performance of language models over time.\\n\\n4. **Integration**: Langsmith is designed to integrate seamlessly with other tools and platforms, making it easier for developers to incorporate it into their existing workflows.\\n\\nOverall, Langsmith aims to streamline the process of developing applications with large language models, focusing on enhancing their reliability and effectiveness.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 213, 'prompt_tokens': 33, 'total_tokens': 246, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'finish_reason': 'stop', 'logprobs': None} id='run-0ccd0650-44d2-4838-8f10-11d00d5d5240-0' usage_metadata={'input_tokens': 33, 'output_tokens': 213, 'total_tokens': 246, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool designed to enhance and optimize applications built with large language models (LLMs). It provides developers with capabilities for testing, evaluating, tracing, and monitoring their LLM-powered applications. The tool is particularly useful for those working with LangChain, as it integrates seamlessly with the LangChain framework. Langsmith allows users to conduct evaluations of language model outputs, trace the execution of applications to understand how different components interact, and monitor performance to ensure reliability and efficiency. Overall, it aims to streamline the development process and improve the quality of applications leveraging LLMs.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
